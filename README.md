# MLT Talks

## Slides, videos and other resources from MLT Talks.

- The many machine learning ways of Google Translate, **Keith Stevens, Google Japan** (August 2019)
- Artificial Life, **Lana Sinapayen, Sony CSL, ELSI** (August 2019)
- Brain-Machine-Interfaces, Talk & Discussion, **Antonio Lozano, UPCT, Spain** (July 2019)
- Getting started with TensorFlow 2.0, **Josh Gordon, Developer Advocate at Google AI** (April 2019)
- Current capabilties, limitations and future directions of deep learning, **François Chollet, Creator of Keras** (March 2019)
- Deep Neural Networks for Video Applications,  **Alex Conway, NumberBoost** (March 2019)
- Beyond Supervised Driving **Adrien Gaidon, Toyota Research Institute** (March 2019)
 
 
#  The many machine learning ways of Google Translate, Keith Stevens (Google Japan)

### Talk
Keith covers recent innovations in machine translation published by the team behind Google Translate. Learn how these models are getting bigger, how they're solving more complex tasks like simultaneous translation, and how embedding methods can be used to find and clean data. He goes into depth about what problem each of these efforts are trying to solve, hear what new approaches are being used, and detail lessons learned while working on these challenges.

### Speaker Bio
Keith Stevens has been on Google Translate for nearly years 7 years. His primary focus has been finding or creating the best data possible for improving Google Translate. This work has ranged from Crowdsourcing systems to neural based data cleaning techniques and automated parallel data mining.

[<p align="center"><img src="https://github.com/Machine-Learning-Tokyo/MLT_Talks/blob/master/images/keith_stevens.png" width="600"></p>](https://github.com/Machine-Learning-Tokyo/MLT_Talks/blob/master/slides/keith_stevens.pdf)

# Artificial Life, Lana Sinapayen (Sony CSL, ELSI)

### Talk
Artificial Life is a little known field spanning disciplines as diverse as Informatics, Chemistry and Robotics. Lana will give a brief overview of the field and its main research questions.

### Speaker Bio
LANA SINAPAYEN is and Artificial Life and Artificial Intelligence researcher. Her main interests are the emergence of cognitive functions such as predictive coding, and evolutionary dynamics leading to open ended systems. Artificial Life is a little known field spanning disciplines as diverse as Informatics, Chemistry and Robotics. In her talk she will give a brief overview of the field and its main research questions.

[<p align="center"><img src="https://github.com/Machine-Learning-Tokyo/MLT_Talks/blob/master/images/lana_alife.png" width="600"></p>](https://bit.ly/2z5orEb)


# Brain-Machine-Interfaces, Antonio Lozano (UPCT Spain)

### Talk
Neural engineering and AI are making rapid progress, and new opportunities for synergy arise. We are facing the challenge of creating neuroprosthesis designed to interface with the visual cortex in order to restore a limited but useful visual sense to these blind patients. This talk will look at neural engineering, some of the advances that highly multidisciplinary teams of scientists and engineers are making in different parts of the world, including Neuralink's new brain interfaces, and some of the future challenges that we face in order to improve people's lives. Antonio will also introduce a new framework -NeuroLight- based on Convolutional Neural Networks, created to encode visual information and transmit this it in a meaningful way to the human brain through a neural prosthesis.

### Speaker Bio
ANTONIO LOZANO is an Industrial Engineer, and Intel's Software Innovator. He's pursuing a PhD in Information and Communications Engineering at UPCT, Spain, collaborating with the Neuroengineering Biomedical Research Group at UMH, towards the goal of creating a cortical visual neuroprosthesis for the blind. Recently, he visited Tokyo Institute of Technology as a visiting junior fellow researcher.

- [Development of a Cortical Visual Neuroprosthesis for the Blind (CORTIVIS project)](https://clinicaltrials.gov/ct2/show/NCT02983370)
- [Biomedical Neuroengineering Research Group, UMH, Spain](https://nbio.umh.es/)

[<p align="center"><img src="https://github.com/Machine-Learning-Tokyo/MLT_Talks/blob/master/images/antonio_lozano.png" width="600"></p>](https://github.com/Machine-Learning-Tokyo/MLT_Talks/blob/master/slides/MLT_Antonio.pdf)


# Getting started with TensorFlow 2.0, Josh Gordon (Google AI)

### Talk
TensorFlow 2.0 is all about ease of use. In this 45 minute talk, I'll cover best practices for beginners and experts, and point you to the latest code examples you can try for each. I'll cover the Keras Sequential, Functional, and Subclassing APIs, as well as built-in training loops, and how to write a custom training loop using a GradientTape. To wrap it up, I'll give a quick summary of a few announcements and updates from the TensorFlow Developer Summit.

### Speaker Bio
Josh Gordon is a Developer Advocate at Google AI, and also teaches Applied Deep Learning at Columbia University, and Machine Learning at Pace University. He has over a decade of machine learning experience to share. You can find him on Twitter at @random_forests.

[<p align="center"><img src="https://github.com/Machine-Learning-Tokyo/MLT_Talks/blob/master/images/josh_gordon.png" width="600"></p>](https://github.com/Machine-Learning-Tokyo/MLT_Talks/blob/master/slides/Josh_Gordon_Google_AI.pdf)


 
# Current capabilties, limitations and future directions of deep learning, François Chollet (Creator of Keras, Google)

### Talk
Deep learning has had amazing successes in recent years. But can it lead to Strong AI? The goal of this talk is to zoom out a little bit -- to look at how deep learning really works, to look at its current limits, and to try to see the road ahead for AI.

### Speaker Bio
François Chollet is the Creator of Keras (keras.io), a leading deep learning API, and author of the textbook "Deep Learning with Python". He is also a machine learning researcher at Google Brain and a contributor to the TensorFlow machine learning platform.

[<p align="center"><img src="https://github.com/Machine-Learning-Tokyo/MLT_Talks/blob/master/images/chollet_recap.png" width="600"></p>](https://www.youtube.com/watch?v=B6w4-_5lcUA)

[<p align="center"><img src="https://github.com/Machine-Learning-Tokyo/MLT_Talks/blob/master/images/chollet.png" width="600"></p>](https://github.com/Machine-Learning-Tokyo/MLT_Talks/blob/master/slides/Francois_Chollet.pdf)


# Deep Neural Networks for Video Applications, Alex Conway (NumberBoost)

### Talk
Most CCTV video cameras exist as a sort of time machine for insurance purposes. Deep neural networks make it easy to convert video into data which can then be used to trigger real-time anomaly alerts and optimize complex business processes. Deep learning can also be used in academic research to speed up labeling of video recorded from the point of view of animals wearing go-pros. This talk will present some theory of deep neural networks for video applications as well as academic research and several applied real-world industrial examples.

### Speaker Bio
Alex is the Founder and Head of Data Science at NumberBoost, a startup based in Cape Town that builds custom A.I. solutions focused on real-time computer vision using deep learning, edge computing and privacy-preserving federated machine learning. NumberBoost has won startup competitions with MultiChoice, Mercedes-Benz, Lloyd's Register in London and NTT Data Japan. He organizes the Cape Town Machine Learning and Deep Learning Meetup groups and chaired the organizing committee for the 2018 Deep Learning IndabaX conference in Cape Town.


[<p align="center"><img src="https://github.com/Machine-Learning-Tokyo/MLT_Talks/blob/master/images/numberboost.png" width="600"></p>](https://www.slideshare.net/AlexConway2/machine-learning-tokyo-deep-neural-networks-for-video-numberboost)

# Beyond Supervised Driving, Adrien Gaidon (Toyota Research Institute)

### Talk
Crowd-sourced steering does not sound as appealing as automated driving. We need to go beyond supervised learning for automated driving, including for computer vision problems seeing great progress with strong supervision today. First, we will motivate why this is required for long-term large-scale autonomous robots. Second, we will discuss recent state-of-the-art results obtained in the ML team at Toyota Research Institute (TRI) for unsupervised domain adaptation from simulation and self-supervised depth and pose prediction from monocular imagery. Finally, I will talk about how we actually scale to large datasets using our cloud infrastructure and distributed deep learning.

### Speaker Bio
Adrien Gaidon is the Manager of the Machine Learning team and a Senior Research Scientist at the Toyota Research Institute (TRI) in Los Altos, CA, USA, working on open problems in world-scale learning for autonomous driving. He received his PhD from Microsoft Research - Inria Paris in 2012 and has over a decade of experience in academic and industrial Computer Vision, with over 30 publications, top entries in international Computer Vision competitions, multiple best reviewer awards, international press coverage for his work on Deep Learning with simulation, and was a guest editor for the International Journal of Computer Vision. You can find him on LinkedIn (https://www.linkedin.com/in/adrien-gaidon-63ab2358/) and Twitter (www.twitter.com/adnothing).


[<p align="center"><img src="https://github.com/Machine-Learning-Tokyo/MLT_Talks/blob/master/images/tri-ad.png" width="600"></p>](https://www.youtube.com/watch?v=mzNQp2t8j10)
